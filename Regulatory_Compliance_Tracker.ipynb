{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "h2ci2h9omSCG",
        "outputId": "93d5b722-0889-424c-8242-a6a6abe0f546"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-de37e141-edae-488b-a9a1-bf2efa40b60e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-de37e141-edae-488b-a9a1-bf2efa40b60e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving tml_ar_2025.pdf to tml_ar_2025.pdf\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# This will open a file chooser dialog\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.listdir()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k76WYms8pzab",
        "outputId": "147fd70e-dd9c-4099-dd68-3bc491629e85"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " 'infosys_ar_2025.pdf',\n",
              " 'wipro_ar_2025.pdf',\n",
              " 'tml_ar_2025.pdf',\n",
              " 'hcltech_ar_2025.pdf',\n",
              " 'tcs_ar_2025.pdf',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf\n",
        "from pypdf import PdfReader\n",
        "\n",
        "files = [\n",
        "    \"infosys_ar_2025.pdf\",\n",
        "    \"tcs_ar_2025.pdf\",\n",
        "    \"wipro_ar_2025.pdf\",\n",
        "    \"hcltech_ar_2025.pdf\",\n",
        "    \"tml_ar_2025.pdf\"\n",
        "]\n",
        "\n",
        "for f in files:\n",
        "    try:\n",
        "        reader = PdfReader(f)\n",
        "        print(f\"{f}: ‚úîÔ∏è Readable ‚Äî Pages:\", len(reader.pages))\n",
        "    except Exception as e:\n",
        "        print(f\"{f}: ‚ùå Cannot read ‚Äî {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UVYHTAxqIuf",
        "outputId": "5c8e68f1-ff13-4584-c825-15eb704e32b9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.3.0)\n",
            "infosys_ar_2025.pdf: ‚úîÔ∏è Readable ‚Äî Pages: 369\n",
            "tcs_ar_2025.pdf: ‚úîÔ∏è Readable ‚Äî Pages: 169\n",
            "wipro_ar_2025.pdf: ‚úîÔ∏è Readable ‚Äî Pages: 520\n",
            "hcltech_ar_2025.pdf: ‚úîÔ∏è Readable ‚Äî Pages: 423\n",
            "tml_ar_2025.pdf: ‚úîÔ∏è Readable ‚Äî Pages: 682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests beautifulsoup4 pdfplumber"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEfTex8lrQbM",
        "outputId": "4968b790-410f-460b-b687-fd75dbbb9425"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.8-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Collecting pdfminer.six==20251107 (from pdfplumber)\n",
            "  Downloading pdfminer_six-20251107-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (11.3.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-5.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (67 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251107->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.23)\n",
            "Downloading pdfplumber-0.11.8-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20251107-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m105.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-5.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20251107 pdfplumber-0.11.8 pypdfium2-5.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"https://www.thehindu.com/business/feeder/default.rss\"\n",
        "\n",
        "response = requests.get(url)\n",
        "response.raise_for_status()\n",
        "\n",
        "soup = BeautifulSoup(response.text, \"xml\")\n",
        "\n",
        "items = soup.find_all(\"item\")\n",
        "\n",
        "for item in items[:10]:\n",
        "    print(item.title.text)\n",
        "    print(item.link.text)\n",
        "    print(item.pubDate.text)\n",
        "    print(\"-\" * 40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1SCIbY5ry4m",
        "outputId": "e77a239e-3b6c-4cfc-d4e9-e0be8e1e636c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time to sort out India‚Äôs cereal mess\n",
            "https://www.thehindu.com/opinion/lead/time-to-sort-out-indias-cereal-mess/article70295623.ece\n",
            "Wed, 19 Nov 2025 00:16:00 +0530\n",
            "----------------------------------------\n",
            "Russia to soon approve nearly 25 Indian fishery units for exports\n",
            "https://www.thehindu.com/business/russia-to-soon-approve-nearly-25-indian-fishery-units-for-exports/article70296204.ece\n",
            "Tue, 18 Nov 2025 22:49:29 +0530\n",
            "----------------------------------------\n",
            "Saudi Arabia to get a new budget carrier based in Medina\n",
            "https://www.thehindu.com/business/saudi-arabia-to-get-a-new-budget-carrier-based-in-medina/article70296110.ece\n",
            "Tue, 18 Nov 2025 22:14:32 +0530\n",
            "----------------------------------------\n",
            "Textile, apparel export see sharp decline in October; government rescinds QCO on viscose fibres\n",
            "https://www.thehindu.com/business/Industry/textile-apparel-export-see-sharp-decline-in-oct-government-rescinds-qco-on-viscose-fibres/article70295928.ece\n",
            "Tue, 18 Nov 2025 21:36:34 +0530\n",
            "----------------------------------------\n",
            "Physicswallah debuts at ‚Çπ145 with 33% premium\n",
            "https://www.thehindu.com/business/physicswallah-debuts-at-145-with-33-premium/article70294882.ece\n",
            "Tue, 18 Nov 2025 21:17:07 +0530\n",
            "----------------------------------------\n",
            "PVV Infra signs MoU to invest ‚Çπ650 crore in Solar Cell unit in Andhra Pradesh\n",
            "https://www.thehindu.com/business/pvv-infra-signs-mou-to-invest-650-crore-in-solar-cell-unit-in-andhra-pradesh/article70295200.ece\n",
            "Tue, 18 Nov 2025 21:10:57 +0530\n",
            "----------------------------------------\n",
            "Watch: How is India responding to calls for shipping decarbonisation?\n",
            "https://www.thehindu.com/videos/watch-how-is-india-responding-to-calls-for-shipping-decarbonisation/article70294669.ece\n",
            "Tue, 18 Nov 2025 18:17:29 +0530\n",
            "----------------------------------------\n",
            "FM Sitharaman holds separate pre-Budget meeting with start-ups for the first time\n",
            "https://www.thehindu.com/business/Economy/fm-sitharaman-holds-separate-pre-budget-meeting-with-start-ups-for-the-first-time/article70294297.ece\n",
            "Tue, 18 Nov 2025 17:07:06 +0530\n",
            "----------------------------------------\n",
            "Stock markets halt 6-day rally; Nifty ends below 26,000-mark on profit taking\n",
            "https://www.thehindu.com/business/markets/stock-markets-halt-6-day-rally-nifty-ends-below-26000-mark-on-profit-taking/article70294190.ece\n",
            "Tue, 18 Nov 2025 16:42:59 +0530\n",
            "----------------------------------------\n",
            "Rupee settles 2 paise lower at 88.61 against U.S. dollar\n",
            "https://www.thehindu.com/business/markets/rupee-settles-2-paise-lower-at-8861-against-us-dollar/article70294184.ece\n",
            "Tue, 18 Nov 2025 16:28:50 +0530\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "import os\n",
        "\n",
        "# Your existing PDF file names\n",
        "pdf_files = [\n",
        "    \"infosys_ar_2025.pdf\",\n",
        "    \"tcs_ar_2025.pdf\",\n",
        "    \"wipro_ar_2025.pdf\",\n",
        "    \"hcltech_ar_2025.pdf\",\n",
        "    \"tml_ar_2025.pdf\"\n",
        "]\n",
        "\n",
        "extracted_text = {}  # dictionary to store text from each file\n",
        "\n",
        "for pdf_path in pdf_files:\n",
        "    if not os.path.exists(pdf_path):\n",
        "        print(f\"‚ùå File not found: {pdf_path}\")\n",
        "        continue\n",
        "\n",
        "    print(f\"üìÑ Extracting: {pdf_path}\")\n",
        "\n",
        "    try:\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            full_text = \"\"\n",
        "            for page in pdf.pages:\n",
        "                text = page.extract_text()\n",
        "                if text:\n",
        "                    full_text += text + \"\\n\"\n",
        "\n",
        "        extracted_text[pdf_path] = full_text\n",
        "\n",
        "        # Save text output\n",
        "        txt_path = pdf_path.replace(\".pdf\", \".txt\")\n",
        "        with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(full_text)\n",
        "\n",
        "        print(f\"‚úÖ Saved extracted text ‚Üí {txt_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error processing {pdf_path}: {e}\")\n",
        "\n",
        "print(\"\\nüéâ All PDF text extraction completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AGUyyY0SyFJH",
        "outputId": "f180aeef-60a2-4b50-ae90-1bcaef74a06f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÑ Extracting: infosys_ar_2025.pdf\n",
            "‚úÖ Saved extracted text ‚Üí infosys_ar_2025.txt\n",
            "üìÑ Extracting: tcs_ar_2025.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P1' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P2' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P3' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P4' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P5' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P6' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P7' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P8' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P9' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P10' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P11' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P12' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P13' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P14' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P15' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P16' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P17' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P18' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P19' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P20' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P21' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P22' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P23' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P24' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P25' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P26' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P27' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P28' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P29' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P30' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P31' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P32' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P33' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P34' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P35' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P36' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P37' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P38' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P39' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P40' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P41' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P42' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P43' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P44' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P45' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P46' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P47' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P48' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P49' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P50' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P51' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P52' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P53' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P1' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P2' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P1' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P2' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P3' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P4' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P5' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P6' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P7' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P8' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P9' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P10' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P11' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P12' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P13' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P14' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P15' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P16' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P17' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P18' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P19' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P20' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P21' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P22' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P23' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P24' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P25' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P26' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P1' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P2' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P3' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P4' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P5' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P6' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P7' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P8' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P9' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P10' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P11' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P12' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P13' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P14' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P15' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P16' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P17' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P18' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P19' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P20' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P21' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P22' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P23' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P24' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P25' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P26' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P1' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P1' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P2' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P3' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P4' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P5' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P6' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P7' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P8' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P9' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P10' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P11' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P12' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P13' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P14' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P15' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P16' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P17' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P18' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P19' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P20' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P21' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P22' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P23' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P24' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P25' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P26' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P1' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P2' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P3' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P4' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P5' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P6' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P7' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P8' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P9' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P10' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P11' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P12' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P13' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P14' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P15' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P16' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P17' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P18' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P19' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P20' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P21' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P22' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P23' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P24' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P25' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P26' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P27' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P28' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P29' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P30' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P31' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P32' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P33' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P34' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P35' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P36' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P37' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P38' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P39' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P40' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P41' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P42' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P43' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P44' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P45' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P46' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P47' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P48' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P49' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P50' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P51' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P52' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P53' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P1' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P2' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P3' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P4' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P5' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P6' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P7' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P8' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P9' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P10' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P11' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P12' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P13' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P14' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P15' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P16' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P17' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P18' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P19' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P20' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P21' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P22' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P23' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P24' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P25' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P26' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P27' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P28' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P29' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P30' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P31' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P32' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P33' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P34' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P35' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray stroke color because /'P36' is an invalid float value\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Saved extracted text ‚Üí tcs_ar_2025.txt\n",
            "üìÑ Extracting: wipro_ar_2025.pdf\n",
            "‚úÖ Saved extracted text ‚Üí wipro_ar_2025.txt\n",
            "üìÑ Extracting: hcltech_ar_2025.pdf\n",
            "‚úÖ Saved extracted text ‚Üí hcltech_ar_2025.txt\n",
            "üìÑ Extracting: tml_ar_2025.pdf\n",
            "‚úÖ Saved extracted text ‚Üí tml_ar_2025.txt\n",
            "\n",
            "üéâ All PDF text extraction completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_brsr_compliance_score(text, keywords):\n",
        "    \"\"\"\n",
        "    Calculate a simple BRSR compliance score based on presence of keywords.\n",
        "\n",
        "    Parameters:\n",
        "    - text (str): Extracted text from a report.\n",
        "    - keywords (list of str): List of keywords/phrases to look for in the text.\n",
        "\n",
        "    Returns:\n",
        "    - score (float): Compliance score as a percentage (0-100).\n",
        "    - keyword_counts (dict): Count of each keyword found.\n",
        "    \"\"\"\n",
        "    text_lower = text.lower()\n",
        "    keyword_counts = {kw: text_lower.count(kw.lower()) for kw in keywords}\n",
        "    found_keywords = sum(1 for count in keyword_counts.values() if count > 0)\n",
        "    total_keywords = len(keywords)\n",
        "    score = (found_keywords / total_keywords) * 100 if total_keywords > 0 else 0\n",
        "    return score, keyword_counts\n",
        "\n",
        "# Example usage:\n",
        "keywords = [\n",
        "    \"Sustainability Report\",\n",
        "    \"Greenhouse Gas Emissions\",\n",
        "    \"Stakeholder Engagement\",\n",
        "    \"Governance Policies\",\n",
        "    \"Employee Wellbeing\",\n",
        "    \"Human Rights\",\n",
        "    \"Materiality Assessment\",\n",
        "    \"Data Protection\",\n",
        "    \"Privacy Impact Assessment\",\n",
        "    \"Business Responsibility and Sustainability Report\"\n",
        "]\n",
        "\n",
        "# Assuming 'extracted_text' contains the text from a company's BRSR document\n",
        "# score, counts = calculate_brsr_compliance_score(extracted_text, keywords)\n",
        "# print(f\"Compliance Score: {score}%\")\n",
        "# print(\"Keyword Counts:\", counts)"
      ],
      "metadata": {
        "id": "GlogPuEY1uQD"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BRSR Compliance Engine (TXT input version)\n",
        "# Run in Google Colab or local Python. Assumes the 5 TXT files already exist in working dir.\n",
        "\n",
        "# Install required packages (uncomment and run if not installed)\n",
        "!pip install rapidfuzz pandas openpyxl\n",
        "\n",
        "# Imports\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import math\n",
        "from datetime import datetime\n",
        "from collections import defaultdict, Counter\n",
        "import pandas as pd\n",
        "from rapidfuzz import fuzz\n",
        "\n",
        "# === Configuration (your TXT filenames) ===\n",
        "TXT_FILES = [\n",
        "    \"infosys_ar_2025.txt\",\n",
        "    \"tcs_ar_2025.txt\",\n",
        "    \"wipro_ar_2025.txt\",\n",
        "    \"hcltech_ar_2025.txt\",\n",
        "    \"tml_ar_2025.txt\"\n",
        "]\n",
        "\n",
        "# Keywords grouped by pillar with example weights (tweak as needed)\n",
        "BRSR_KEYWORDS = {\n",
        "    \"Environment\": {\n",
        "        \"greenhouse gas\": 2.0,\n",
        "        \"ghg emissions\": 2.0,\n",
        "        \"carbon footprint\": 2.0,\n",
        "        \"energy consumption\": 1.5,\n",
        "        \"renewable\": 1.8,\n",
        "        \"emissions\": 1.5,\n",
        "        \"water consumption\": 1.2,\n",
        "        \"waste management\": 1.3,\n",
        "        \"climate change\": 2.0,\n",
        "        \"net zero\": 2.0,\n",
        "        \"sustainability report\": 1.0\n",
        "    },\n",
        "    \"Social\": {\n",
        "        \"stakeholder engagement\": 1.8,\n",
        "        \"employee wellbeing\": 1.6,\n",
        "        \"human rights\": 2.0,\n",
        "        \"community development\": 1.5,\n",
        "        \"labor practices\": 1.6,\n",
        "        \"diversity\": 1.7,\n",
        "        \"training and development\": 1.2,\n",
        "        \"health and safety\": 1.8\n",
        "    },\n",
        "    \"Governance\": {\n",
        "        \"governance policy\": 1.8,\n",
        "        \"board composition\": 1.6,\n",
        "        \"ethics\": 1.5,\n",
        "        \"anti-corruption\": 2.0,\n",
        "        \"risk management\": 1.8,\n",
        "        \"audit committee\": 1.2,\n",
        "        \"whistleblower\": 1.4\n",
        "    },\n",
        "    \"Disclosure\": {\n",
        "        \"materiality assessment\": 2.0,\n",
        "        \"disclosure\": 1.5,\n",
        "        \"data protection\": 1.8,\n",
        "        \"privacy impact assessment\": 2.0,\n",
        "        \"reporting framework\": 1.5,\n",
        "        \"brsr\": 2.0,\n",
        "        \"business responsibility and sustainability report\": 2.0\n",
        "    },\n",
        "    \"Stakeholder\": {\n",
        "        \"stakeholder\": 1.5,\n",
        "        \"grievance\": 1.5,\n",
        "        \"engagement\": 1.2,\n",
        "        \"supplier\": 1.0,\n",
        "        \"customer\": 1.0\n",
        "    }\n",
        "}\n",
        "\n",
        "# Parameters\n",
        "FUZZY_THRESHOLD = 80            # 0-100 fuzzy match threshold\n",
        "SNIPPETS_PER_KEYWORD = 3        # how many context snippets to show per keyword\n",
        "SUMMARY_SENTENCES = 5           # number of sentences for extractive summary\n",
        "ASSUME_FULL_MENTIONS = 3        # heuristic freq assumed as \"full\" for normalization\n",
        "\n",
        "# === Utility functions ===\n",
        "\n",
        "def load_txt(path):\n",
        "    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        return f.read()\n",
        "\n",
        "def split_sentences(text):\n",
        "    # Simple sentence splitter (keeps reasonably short sentences)\n",
        "    sentences = re.split(r'(?<=[\\.\\?\\!\\n])\\s+', text)\n",
        "    return [s.strip() for s in sentences if s.strip()]\n",
        "\n",
        "def find_keyword_counts_and_snippets(text, keywords_by_pillar,\n",
        "                                     fuzzy_threshold=FUZZY_THRESHOLD,\n",
        "                                     snippets_per_kw=SNIPPETS_PER_KEYWORD):\n",
        "    text_lower = text.lower()\n",
        "    sentences = split_sentences(text)\n",
        "    pillar_results = {}\n",
        "    global_counts = Counter()\n",
        "    snippets = defaultdict(list)\n",
        "\n",
        "    for pillar, kws in keywords_by_pillar.items():\n",
        "        pillar_counts = {}\n",
        "        pillar_weighted_score = 0.0\n",
        "        total_possible_weight = sum(kws.values())\n",
        "\n",
        "        for kw, weight in kws.items():\n",
        "            kw_low = kw.lower()\n",
        "            # direct occurrences\n",
        "            direct_count = text_lower.count(kw_low)\n",
        "            count = direct_count\n",
        "\n",
        "            # sentence-level fuzzy search to capture variations\n",
        "            for s in sentences:\n",
        "                s_low = s.lower()\n",
        "                # skip if direct match already counted in this sentence\n",
        "                if kw_low in s_low:\n",
        "                    if len(snippets[kw]) < snippets_per_kw:\n",
        "                        snippets[kw].append((s[:400], \"direct\"))\n",
        "                    continue\n",
        "                score = fuzz.partial_ratio(kw_low, s_low)\n",
        "                if score >= fuzzy_threshold:\n",
        "                    count += 1\n",
        "                    if len(snippets[kw]) < snippets_per_kw:\n",
        "                        snippets[kw].append((s[:400], f\"fuzzy({score})\"))\n",
        "\n",
        "            pillar_counts[kw] = count\n",
        "            global_counts[kw] += count\n",
        "\n",
        "            # presence-based weighted contribution with diminishing returns by frequency\n",
        "            presence = 1 if count > 0 else 0\n",
        "            freq_factor = math.log1p(count)\n",
        "            pillar_weighted_score += weight * presence * freq_factor\n",
        "\n",
        "        # Normalize pillar score to 0-100 using heuristic\n",
        "        denom = total_possible_weight * math.log1p(ASSUME_FULL_MENTIONS)\n",
        "        pillar_pct = min(100.0, (pillar_weighted_score / denom) * 100.0) if denom > 0 else 0.0\n",
        "\n",
        "        pillar_results[pillar] = {\n",
        "            \"counts\": pillar_counts,\n",
        "            \"weighted_raw\": round(pillar_weighted_score, 4),\n",
        "            \"score_pct\": round(pillar_pct, 2)\n",
        "        }\n",
        "\n",
        "    return pillar_results, dict(global_counts), dict(snippets)\n",
        "\n",
        "def extract_top_sentences(text, keywords_by_pillar, top_n=SUMMARY_SENTENCES):\n",
        "    sentences = split_sentences(text)\n",
        "    flat_kws = [kw.lower() for p in keywords_by_pillar.values() for kw in p.keys()]\n",
        "    scored = []\n",
        "    for s in sentences:\n",
        "        s_low = s.lower()\n",
        "        score = 0.0\n",
        "        for kw in flat_kws:\n",
        "            if kw in s_low:\n",
        "                score += 2.0\n",
        "            else:\n",
        "                # small fuzzy contribution\n",
        "                score += (fuzz.partial_ratio(kw, s_low) / 100.0) * 0.1\n",
        "        if score > 0:\n",
        "            scored.append((score, s))\n",
        "    scored.sort(reverse=True, key=lambda x: x[0])\n",
        "    top_sents = [s for _, s in scored[:top_n]]\n",
        "    # fallback: if not enough scored sentences, pick first N sentences\n",
        "    if len(top_sents) < top_n:\n",
        "        top_sents = top_sents + sentences[:(top_n - len(top_sents))]\n",
        "    return \" \".join(top_sents[:top_n])\n",
        "\n",
        "# === Main processing ===\n",
        "\n",
        "# Check files exist\n",
        "found = [f for f in TXT_FILES if os.path.exists(f)]\n",
        "missing = [f for f in TXT_FILES if f not in found]\n",
        "if missing:\n",
        "    print(\"Warning - these TXT files were NOT found and will be skipped:\", missing)\n",
        "    print(\"Proceeding with:\", found)\n",
        "\n",
        "results = []\n",
        "detailed = {}\n",
        "\n",
        "for txt in found:\n",
        "    print(f\"\\nProcessing: {txt}\")\n",
        "    raw_text = load_txt(txt)\n",
        "    chars = len(raw_text)\n",
        "    print(f\" - Characters extracted: {chars:,}\")\n",
        "\n",
        "    # Keyword matching & scoring\n",
        "    pillar_res, global_counts, snippets = find_keyword_counts_and_snippets(\n",
        "        raw_text, BRSR_KEYWORDS, fuzzy_threshold=FUZZY_THRESHOLD, snippets_per_kw=SNIPPETS_PER_KEYWORD)\n",
        "\n",
        "    pillar_scores = {p: pillar_res[p][\"score_pct\"] for p in pillar_res}\n",
        "    overall_score = round(sum(pillar_scores.values()) / len(pillar_scores), 2) if pillar_scores else 0.0\n",
        "\n",
        "    # Summary\n",
        "    summary = extract_top_sentences(raw_text, BRSR_KEYWORDS, top_n=SUMMARY_SENTENCES)\n",
        "\n",
        "    # Missing/low-disclosure keywords (zero mentions)\n",
        "    missing_keywords = [kw for p in BRSR_KEYWORDS.values() for kw in p.keys() if global_counts.get(kw, 0) == 0]\n",
        "\n",
        "    result = {\n",
        "        \"file\": txt,\n",
        "        \"chars_extracted\": chars,\n",
        "        \"num_keywords_mentioned\": sum(1 for v in global_counts.values() if v>0),\n",
        "        **pillar_scores,\n",
        "        \"overall_score\": overall_score,\n",
        "        \"summary\": summary[:1000]  # short snippet\n",
        "    }\n",
        "    results.append(result)\n",
        "\n",
        "    detailed[txt] = {\n",
        "        \"pillar_results\": pillar_res,\n",
        "        \"global_counts\": global_counts,\n",
        "        \"snippets\": snippets,\n",
        "        \"missing_keywords\": missing_keywords\n",
        "    }\n",
        "\n",
        "# === Export results ===\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "outdir = f\"brsr_txt_results_{timestamp}\"\n",
        "os.makedirs(outdir, exist_ok=True)\n",
        "\n",
        "# Summary DataFrame -> CSV & Excel\n",
        "df = pd.DataFrame(results)\n",
        "csv_path = os.path.join(outdir, \"brsr_summary.csv\")\n",
        "xlsx_path = os.path.join(outdir, \"brsr_summary.xlsx\")\n",
        "df.to_csv(csv_path, index=False)\n",
        "df.to_excel(xlsx_path, index=False)\n",
        "print(\"\\nSaved overview files:\", csv_path, \"and\", xlsx_path)\n",
        "\n",
        "# Detailed JSON\n",
        "json_path = os.path.join(outdir, \"brsr_detailed.json\")\n",
        "with open(json_path, \"w\", encoding=\"utf-8\") as jf:\n",
        "    json.dump(detailed, jf, ensure_ascii=False, indent=2)\n",
        "print(\"Saved detailed JSON:\", json_path)\n",
        "\n",
        "# Keyword snippets table\n",
        "rows = []\n",
        "for txt, info in detailed.items():\n",
        "    for kw, cnt in info[\"global_counts\"].items():\n",
        "        snips = info[\"snippets\"].get(kw, [])\n",
        "        snip_text = \" ||| \".join([f\"{s[:250]} [{tag}]\" for s, tag in snips])\n",
        "        rows.append({\"file\": txt, \"keyword\": kw, \"count\": cnt, \"snippets\": snip_text})\n",
        "df_snips = pd.DataFrame(rows)\n",
        "snips_path = os.path.join(outdir, \"keyword_snippets.csv\")\n",
        "df_snips.to_csv(snips_path, index=False)\n",
        "print(\"Saved keyword snippets CSV:\", snips_path)\n",
        "\n",
        "# Save plain text copies (copying source txts) for record\n",
        "for txt in found:\n",
        "    dst = os.path.join(outdir, os.path.basename(txt))\n",
        "    with open(txt, \"r\", encoding=\"utf-8\", errors=\"ignore\") as r, open(dst, \"w\", encoding=\"utf-8\") as w:\n",
        "        w.write(r.read())\n",
        "print(\"Copied source TXT files to output folder.\")\n",
        "\n",
        "# Final print summary\n",
        "print(\"\\n=== BRSR Compliance Summary ===\")\n",
        "print(df.to_string(index=False))\n",
        "print(f\"\\nAll results exported to folder: {outdir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jtdVkJn4-mK",
        "outputId": "b55e9eac-5352-4bf0-c2c5-0091537ebf2e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rapidfuzz\n",
            "  Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/3.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m174.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz\n",
            "Successfully installed rapidfuzz-3.14.3\n",
            "\n",
            "Processing: infosys_ar_2025.txt\n",
            " - Characters extracted: 1,182,121\n",
            "\n",
            "Processing: tcs_ar_2025.txt\n",
            " - Characters extracted: 1,019,737\n",
            "\n",
            "Processing: wipro_ar_2025.txt\n",
            " - Characters extracted: 1,490,568\n",
            "\n",
            "Processing: hcltech_ar_2025.txt\n",
            " - Characters extracted: 1,231,070\n",
            "\n",
            "Processing: tml_ar_2025.txt\n",
            " - Characters extracted: 1,699,968\n",
            "\n",
            "Saved overview files: brsr_txt_results_20251119_021436/brsr_summary.csv and brsr_txt_results_20251119_021436/brsr_summary.xlsx\n",
            "Saved detailed JSON: brsr_txt_results_20251119_021436/brsr_detailed.json\n",
            "Saved keyword snippets CSV: brsr_txt_results_20251119_021436/keyword_snippets.csv\n",
            "Copied source TXT files to output folder.\n",
            "\n",
            "=== BRSR Compliance Summary ===\n",
            "               file  chars_extracted  num_keywords_mentioned  Environment  Social  Governance  Disclosure  Stakeholder  overall_score                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      summary\n",
            "infosys_ar_2025.txt          1182121                      38        100.0   100.0       100.0       100.0        100.0          100.0                  Stakeholder group Whether identified Channels of communication (Email, SMS, newspaper, Frequency of Purpose and scope of engagement\\nas vulnerable or pamphlets, advertisement, community meetings, notice engagement including key topics and concerns raised\\nmarginalized board, website, others (please specify) (Annually/ Half- during such engagement\\n(Yes/No) yearly/ Quarterly\\n/ others ‚Äì please\\nspecify)\\nInvestors No ‚Ä¢ Investors calls, emails, and personal meetings Ongoing ‚Ä¢ To answer queries of investors on\\n‚Ä¢ Analyst meets Infosys‚Äô ambitions and progress\\n‚Ä¢ Conferences (including broker-led events) ‚Ä¢ Build transparency with existing and\\npotential investors\\n‚Ä¢ Quarterly results\\n‚Ä¢ Annual General Meeting\\n‚Ä¢ Sustainability report\\n‚Ä¢ Financial reports\\n‚Ä¢ India stock exchange filings (NSE and BSE)\\n‚Ä¢ US Securities and Exchange Commission (SEC) filings\\n‚Ä¢ Press releases\\n‚Ä¢ Social media\\nEmployees No ‚Ä¢ Employee satisfaction surveys Ongoing ‚Ä¢ Communicate the employee value\\n‚Ä¢ Employee resource groups propositi\n",
            "    tcs_ar_2025.txt          1019737                      38        100.0   100.0       100.0       100.0        100.0          100.0                       Stakeholder engagement 305-3 Other indirect (Scope 3) GHG emissions ‚Ä¢ BRSR 157\\n2-29 Approach to stakeholder engagement ‚Ä¢ BRSR 143 305-4 GHG emissions intensity ‚Ä¢ BRSR 151, 157\\n2-30 Collective bargaining agreements ‚Ä¢ BRSR 138 305-5 Reduction of GHG emissions ‚Ä¢ BRSR 152\\nGRI 3: Material Topics 2021 GRI 306: Waste 2020\\n3-1 Process to determine material topics ‚Ä¢ Stakeholder Engagement 319 306-2 Management of significant waste-related impacts ‚Ä¢ BRSR 135, 136, 155\\nand Identification of 306-3 Waste generated ‚Ä¢ BRSR 153\\nMaterial Topics\\n306-4 Waste diverted from disposal ‚Ä¢ BRSR 153\\n3-2 List of material topics ‚Ä¢ BRSR 130\\n306-5 Waste directed to disposal ‚Ä¢ BRSR 153\\n‚Ä¢ TCS ESG Principles, Material 320\\nTopics and Initiatives GRI 308: Supplier Environmental Assessment 2016\\n3-3 Management of material topics ‚Ä¢ MD&A 88 308-1 New suppliers that were screened using environmental criteria ‚Ä¢ BRSR 135, 158\\n‚Ä¢ BRSR 130, 131, 141, 308-2 Negative environmental impacts in the supply chain and actions ‚Ä¢ BRSR 158\\n14\n",
            "  wipro_ar_2025.txt          1490568                      38        100.0   100.0       100.0       100.0        100.0          100.0                       Abbreviation Expansion\\n1 ABAC Anti-Bribery and Anti-Corruption 41 CoE Center of Excellence\\n2 ACV Annual contract value 42 COO Chief Operation Officer\\n3 ADR American Depositary Receipt 43 COSO Committee of Sponsoring Organizations\\n4 ADS American Depositary Share 44 CRS Cybersecurity and Risk Services\\n5 AE Automobile Engineering 45 CSAT Customer Satisfaction\\n6 AGM Annual General Meeting 46 CSO Chief Sustainability officer\\n7 AHU Air Handling Units 47 CSR Corporate Social Responsibility\\n8 AI Artificial Intelligence 48 CSRD Corporate Sustainability Reporting Directive\\n9 AI/ML Artificial Intelligence/Machine Learning 49 CTO Chief Technology Officer\\n10 AMC Annual Maintenance Contracts 50 CwD Children with Disabilities\\n11 AML Anti- Money Laundering 51 CX Customer Experience\\n12 ANZ Australia and New Zealand 52 CXO Chief Experience Officer\\n13 APAC Asia Pacific 53 DAAI Data, Analytics, and Artificial Intelligence\\n14 APMEA Asia Pacific, Middle East and Africa 54 DASRA Developmental Action, Researc\n",
            "hcltech_ar_2025.txt          1231070                      38        100.0   100.0       100.0       100.0        100.0          100.0 1 rank in 21 categories in\\nthe Institutional Investor\\nResearch Annual Asia Executive\\nTeam survey\\n‚Ä¢Recognized as Top Employer\\n223,420 for three years in a row\\nEmployees\\n‚Ä¢Best-in-class employee\\nexperience and learning\\n8.63M ‚Ä¢Safe and inclusive workplaces\\nHours of employee training ‚Ä¢Stable senior leadership\\n(Total person hours)\\n‚Ä¢Partner to 50% G500\\nenterprises and 40%\\nG2000 enterprises\\n‚Ä¢400+ leadership rankings\\nin analyst recognitions\\nMedium-term strategic objectives\\n‚Ä¢Inclusive growth of local\\n‚Çπ1,680Cr $5M communities\\nIndia CSR HCLTech ‚Ä¢Conservation of environment\\ninvestment Americas Grant in geographies of operation\\n- over 5 Years\\n734,000+ ‚Ä¢Recognized as one of the\\nWorld‚Äôs Most Ethical\\nHours of employee\\nCompanies by Ethisphere for\\ncommunity volunteering\\ntwo years in a row\\n100%\\nOwned buildings Platinum-rated ‚Ä¢Leader in water stewardship\\nby Green Building Councils\\n‚Ä¢Top ESG ratings from\\nleading agencies\\n10.2L 323,445GJ\\n‚Ä¢Employees motivated to be\\nWater consumption Renewable energy climate ch\n",
            "    tml_ar_2025.txt          1699968                      38        100.0   100.0       100.0       100.0        100.0          100.0                 2-10 Nomination and selection of the highest governance body Page 181\\n2-11 Chair of the highest governance body Page 179\\n2-12 Role of the highest governance body in overseeing the Page 182\\nmanagement of impacts\\n2-13 Delegation of responsibility for managing impacts Page 191\\n2-14 Role of the highest governance body in Page 182\\nsustainability reporting\\n2-15 Conflicts of interest Page 185\\n2-16 Communication of critical concerns Page 182\\n2-17 Collective knowledge of the highest governance body Page 183\\n2-18 Evaluation of the performance of the highest Page 181\\ngovernance body\\n2-19 Remuneration policies Page 181\\n2-20 Process to determine remuneration Page 181\\n2-21 Annual total compensation ratio Directors‚Äô Report\\n2-22 Statement on sustainable development strategy Page 88-91\\n2-23 Policy commitments Page 150\\n2-24 Embedding policy commitments Page 150\\n2-25 Processes to remediate negative impacts Page 186\\n2-26 Mechanisms for seeking advice and raising concerns Page 186\\n2-27 Compliance with laws\n",
            "\n",
            "All results exported to folder: brsr_txt_results_20251119_021436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "folder = \"brsr_txt_results_20251119_021436\"\n",
        "shutil.make_archive(folder, 'zip', folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JQfHyU9q5ozi",
        "outputId": "8d0c5031-5027-43b1-96c6-db3db5d09678"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/brsr_txt_results_20251119_021436.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gezA5LIg59xg",
        "outputId": "a7aa6729-2e90-43b3-97ea-1c9bffbc4546"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "drive_output = \"/content/drive/MyDrive/BRSR_Results/\"\n",
        "\n",
        "# Create folder in Drive if it doesn't exist\n",
        "os.makedirs(drive_output, exist_ok=True)\n",
        "\n",
        "# Copy the entire output folder\n",
        "shutil.copytree(outdir, drive_output + outdir, dirs_exist_ok=True)\n",
        "\n",
        "print(\"Results saved permanently to Google Drive at:\", drive_output + outdir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UUrHAI77zfI",
        "outputId": "0a45806b-cb1c-410b-e84f-e9cca2c68ff3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved permanently to Google Drive at: /content/drive/MyDrive/BRSR_Results/brsr_txt_results_20251119_021436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cursor.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS Regulatory_Updates (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    date TEXT NOT NULL,\n",
        "    title TEXT NOT NULL,\n",
        "    link TEXT NOT NULL\n",
        ");\n",
        "\"\"\")\n",
        "\n",
        "cursor.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS Company_Reports (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    company_name TEXT NOT NULL,\n",
        "    report_type TEXT NOT NULL,\n",
        "    report_year INTEGER,\n",
        "    url TEXT NOT NULL,\n",
        "    download_date TEXT\n",
        ");\n",
        "\"\"\")\n",
        "\n",
        "cursor.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS Compliance_Scores (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    report_id INTEGER NOT NULL,\n",
        "    score REAL NOT NULL,\n",
        "    assessment_date TEXT NOT NULL,\n",
        "    keyword_counts TEXT,\n",
        "    FOREIGN KEY (report_id) REFERENCES Company_Reports (id)\n",
        ");\n",
        "\"\"\")\n",
        "\n",
        "conn.commit()\n",
        "print(\"All tables created successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_vFCADb8VvW",
        "outputId": "66e63d51-9cdc-45a3-c288-5a4e08283b88"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tables created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "\n",
        "# Create / connect to your database file\n",
        "conn = sqlite3.connect(\"brsr_database.db\")\n",
        "cursor = conn.cursor()"
      ],
      "metadata": {
        "id": "_R1-R_8i8qLa"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import json\n",
        "\n",
        "# Connect to SQLite database (creates if doesn't exist)\n",
        "conn = sqlite3.connect('brsr_database.db')\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Example function to insert regulatory updates\n",
        "def insert_regulatory_update(date, title, link):\n",
        "    cursor.execute('''\n",
        "        INSERT INTO Regulatory_Updates (date, title, link)\n",
        "        VALUES (?, ?, ?)\n",
        "    ''', (date, title, link))\n",
        "    conn.commit()\n",
        "\n",
        "# Example function to insert company report metadata\n",
        "def insert_company_report(company_name, report_type, report_year, url, download_date):\n",
        "    cursor.execute('''\n",
        "        INSERT INTO Company_Reports (company_name, report_type, report_year, url, download_date)\n",
        "        VALUES (?, ?, ?, ?, ?)\n",
        "    ''', (company_name, report_type, report_year, url, download_date))\n",
        "    conn.commit()\n",
        "    return cursor.lastrowid  # Return inserted report's ID for referencing\n",
        "\n",
        "# Example function to insert compliance score with keyword counts\n",
        "def insert_compliance_score(report_id, score, assessment_date, keyword_counts):\n",
        "    keyword_counts_json = json.dumps(keyword_counts)  # Convert dict to JSON string\n",
        "    cursor.execute('''\n",
        "        INSERT INTO Compliance_Scores (report_id, score, assessment_date, keyword_counts)\n",
        "        VALUES (?, ?, ?, ?)\n",
        "    ''', (report_id, score, assessment_date, keyword_counts_json))\n",
        "    conn.commit()\n",
        "\n",
        "# Usage example:\n",
        "# Insert a regulatory update\n",
        "insert_regulatory_update('2025-11-19', 'New BRSR Circular Released', 'https://www.sebi.gov.in/circular123')\n",
        "\n",
        "# Insert a company report\n",
        "report_id = insert_company_report('Infosys', 'BRSR', 2024, 'https://www.infosys.com/investors/brsr-2024.pdf', '2025-11-18')\n",
        "\n",
        "# Insert compliance score\n",
        "keyword_counts_example = {\n",
        "    'sustainability report': 5,\n",
        "    'greenhouse gas emissions': 3,\n",
        "    'data protection': 2\n",
        "}\n",
        "insert_compliance_score(report_id, 85.0, '2025-11-19', keyword_counts_example)\n",
        "\n",
        "# Close connection when done\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "9HMae05W9XQa"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import sqlite3\n",
        "\n",
        "# Connect to your database\n",
        "conn = sqlite3.connect('brsr_database.db') # Change the name to your .db file\n",
        "\n",
        "# Export data from a table to a CSV file\n",
        "df_scores = pd.read_sql_query(\"SELECT * FROM Compliance_Scores\", conn)\n",
        "df_scores.to_csv('Compliance_Scores.csv', index=False)\n",
        "\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "2U3LlSqV_5fx"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "database_file = 'brsr_database.db' # OR 'compliance_tracker.db'\n",
        "\n",
        "conn = sqlite3.connect(database_file)\n",
        "\n",
        "# Get a list of all tables in the database\n",
        "cursor = conn.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "tables = cursor.fetchall()\n",
        "print(f\"Tables in {database_file}: {tables}\\n\")\n",
        "\n",
        "if tables:\n",
        "    # Print the first 5 rows of the first table found to see the data\n",
        "    first_table_name = tables[0][0]\n",
        "    df = pd.read_sql_query(f\"SELECT * FROM {first_table_name} LIMIT 5\", conn)\n",
        "    print(f\"Sample data from {first_table_name}:\")\n",
        "    print(df)\n",
        "\n",
        "conn.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pU6JfwGNBuuW",
        "outputId": "f555ac77-64b7-410a-caeb-2cfb2fc40a8b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tables in brsr_database.db: [('Regulatory_Updates',), ('sqlite_sequence',), ('Company_Reports',), ('Compliance_Scores',)]\n",
            "\n",
            "Sample data from Regulatory_Updates:\n",
            "   id        date                       title  \\\n",
            "0   1  2025-11-19  New BRSR Circular Released   \n",
            "\n",
            "                                  link  \n",
            "0  https://www.sebi.gov.in/circular123  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "database_file = 'compliance_tracker.db' # The file you want to check\n",
        "\n",
        "try:\n",
        "    conn = sqlite3.connect(database_file)\n",
        "    print(f\"Successfully connected to {database_file}\")\n",
        "\n",
        "    # Get a list of all tables in the database\n",
        "    cursor = conn.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "    tables = cursor.fetchall()\n",
        "    print(f\"Tables in {database_file}: {tables}\\n\")\n",
        "\n",
        "    if tables:\n",
        "        for table_name_tuple in tables:\n",
        "            table_name = table_name_tuple[0]\n",
        "            print(f\"--- Data from table: {table_name} ---\")\n",
        "\n",
        "            # Use pandas to read a few rows of data from the table\n",
        "            df = pd.read_sql_query(f\"SELECT * FROM {table_name} LIMIT 5\", conn)\n",
        "            print(df)\n",
        "            print(\"\\n\")\n",
        "    else:\n",
        "        print(\"This database file contains no tables.\")\n",
        "\n",
        "except sqlite3.Error as e:\n",
        "    print(f\"An error occurred while accessing the database: {e}\")\n",
        "\n",
        "finally:\n",
        "    if conn:\n",
        "        conn.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwCqyLjdCGwJ",
        "outputId": "84a96134-6787-4fd4-b94b-7acf85dcfb72"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully connected to compliance_tracker.db\n",
            "Tables in compliance_tracker.db: []\n",
            "\n",
            "This database file contains no tables.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import json\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "conn = sqlite3.connect(\"brsr_database.db\")\n",
        "cursor = conn.cursor()\n",
        "\n",
        "print(\"Connected to brsr_database.db\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDrDv3jsDwIW",
        "outputId": "6694b6dc-3ab1-4b6a-c9fc-71aaee8a57df"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connected to brsr_database.db\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_brsr_compliance_score(text, keywords):\n",
        "    text_lower = text.lower()\n",
        "    keyword_counts = {kw: text_lower.count(kw.lower()) for kw in keywords}\n",
        "    found_keywords = sum(1 for count in keyword_counts.values() if count > 0)\n",
        "    total = len(keywords)\n",
        "    score = (found_keywords / total) * 100 if total else 0\n",
        "    return score, keyword_counts"
      ],
      "metadata": {
        "id": "GM38poOuD11r"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_company_report(company_name, report_type, report_year, url, download_date):\n",
        "    cursor.execute(\"\"\"\n",
        "        INSERT INTO Company_Reports (company_name, report_type, report_year, url, download_date)\n",
        "        VALUES (?, ?, ?, ?, ?)\n",
        "    \"\"\", (company_name, report_type, report_year, url, download_date))\n",
        "    conn.commit()\n",
        "    return cursor.lastrowid\n",
        "\n",
        "def insert_compliance_score(report_id, score, assessment_date, keyword_counts):\n",
        "    keyword_json = json.dumps(keyword_counts)\n",
        "    cursor.execute(\"\"\"\n",
        "        INSERT INTO Compliance_Scores (report_id, score, assessment_date, keyword_counts)\n",
        "        VALUES (?, ?, ?, ?)\n",
        "    \"\"\", (report_id, score, assessment_date, keyword_json))\n",
        "    conn.commit()"
      ],
      "metadata": {
        "id": "RCZRMWBYD60G"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keywords = [\n",
        "    \"Sustainability Report\",\n",
        "    \"Greenhouse Gas Emissions\",\n",
        "    \"Stakeholder Engagement\",\n",
        "    \"Governance Policies\",\n",
        "    \"Employee Wellbeing\",\n",
        "    \"Human Rights\",\n",
        "    \"Materiality Assessment\",\n",
        "    \"Data Protection\",\n",
        "    \"Privacy Impact Assessment\",\n",
        "    \"Business Responsibility and Sustainability Report\"\n",
        "]"
      ],
      "metadata": {
        "id": "qyAsHKcOD9-z"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt_folder = \"/content/brsr_txt_results_20251119_021436\"   # <-- update if different\n",
        "\n",
        "company_map = {\n",
        "    \"infosys\": \"Infosys\",\n",
        "    \"tcs\": \"TCS\",\n",
        "    \"wipro\": \"Wipro\",\n",
        "    \"hcltech\": \"HCLTech\",\n",
        "    \"tml\": \"Tata Motors\"\n",
        "}\n",
        "\n",
        "for filename in os.listdir(txt_folder):\n",
        "    if filename.endswith(\".txt\"):\n",
        "        file_path = os.path.join(txt_folder, filename)\n",
        "\n",
        "        # detect company from filename\n",
        "        key = filename.split(\"_\")[0].lower()\n",
        "        company_name = company_map.get(key, \"Unknown\")\n",
        "\n",
        "        # read text\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            text = f.read()\n",
        "\n",
        "        # score\n",
        "        score, counts = calculate_brsr_compliance_score(text, keywords)\n",
        "\n",
        "        # insert into DB\n",
        "        report_id = insert_company_report(\n",
        "            company_name=company_name,\n",
        "            report_type=\"Annual Report\",\n",
        "            report_year=2025,\n",
        "            url=\"N/A\",\n",
        "            download_date=str(datetime.date.today())\n",
        "        )\n",
        "\n",
        "        insert_compliance_score(\n",
        "            report_id=report_id,\n",
        "            score=score,\n",
        "            assessment_date=str(datetime.date.today()),\n",
        "            keyword_counts=counts\n",
        "        )\n",
        "\n",
        "        print(f\"{company_name}: Inserted with score {score:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EDnh1R4EDaa",
        "outputId": "ac66d708-0f34-4608-8507-a0ef79718a58"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HCLTech: Inserted with score 100.00\n",
            "Tata Motors: Inserted with score 80.00\n",
            "TCS: Inserted with score 80.00\n",
            "Infosys: Inserted with score 80.00\n",
            "Wipro: Inserted with score 100.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh *.db"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Der5WdnpEwQd",
        "outputId": "5ddf3eaa-6c83-4a4f-f35c-48369ceaba4e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 20K Nov 19 03:03 brsr_database.db\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conn = sqlite3.connect('brsr_database.db')"
      ],
      "metadata": {
        "id": "ACY1POaCE3C5"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Connect to the correct DB\n",
        "conn = sqlite3.connect('brsr_database.db')\n",
        "\n",
        "# List of tables to export\n",
        "tables = [\"Company_Reports\", \"Compliance_Scores\", \"Regulatory_Updates\"]\n",
        "\n",
        "output_folder = \"/content/drive/MyDrive/BRSR_Results/CSV_Exports/\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "for table in tables:\n",
        "    try:\n",
        "        df = pd.read_sql_query(f\"SELECT * FROM {table}\", conn)\n",
        "        csv_path = os.path.join(output_folder, f\"{table}.csv\")\n",
        "        df.to_csv(csv_path, index=False)\n",
        "        print(f\"‚úÖ Exported: {csv_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Skipped {table}: {e}\")\n",
        "\n",
        "conn.close()\n",
        "\n",
        "print(\"\\nüéâ All available tables exported successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzJrM426FGGz",
        "outputId": "772aab87-4fea-4059-cbaf-b51ee110f353"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Exported: /content/drive/MyDrive/BRSR_Results/CSV_Exports/Company_Reports.csv\n",
            "‚úÖ Exported: /content/drive/MyDrive/BRSR_Results/CSV_Exports/Compliance_Scores.csv\n",
            "‚úÖ Exported: /content/drive/MyDrive/BRSR_Results/CSV_Exports/Regulatory_Updates.csv\n",
            "\n",
            "üéâ All available tables exported successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  # if not already mounted\n",
        "\n",
        "# Example: Save entire output folder\n",
        "import shutil\n",
        "shutil.copytree(outdir, f\"/content/drive/MyDrive/BRSR_Results/{outdir}\", dirs_exist_ok=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "4NuaRtwrHZf5",
        "outputId": "475e657e-461c-42c0-cb53-a63c309b5b01"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/BRSR_Results/brsr_txt_results_20251119_021436'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conn.close()"
      ],
      "metadata": {
        "id": "Xv18J-TxIAPT"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/drive/MyDrive/BRSR_Automation/brsr_automation.py\n",
        "# paste the ENTIRE automation code here exactly as-is\n",
        "\n",
        "# One-click BRSR Automation Engine (Colab-ready)\n",
        "# Places outputs in your Drive and updates brsr_database.db\n",
        "# Assumes Drive path: /content/drive/MyDrive/BRSR_Reports/\n",
        "\n",
        "# -----------------------\n",
        "# Install / imports\n",
        "# -----------------------\n",
        "!pip install -q pdfplumber rapidfuzz pandas openpyxl pytesseract pillow\n",
        "!apt-get update -qq\n",
        "!apt-get install -qq -y tesseract-ocr poppler-utils\n",
        "\n",
        "import os, sys, io, json, sqlite3, shutil, math, datetime\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "import pdfplumber\n",
        "from rapidfuzz import fuzz\n",
        "import pandas as pd\n",
        "import pytesseract\n",
        "\n",
        "# -----------------------\n",
        "# Configuration\n",
        "# -----------------------\n",
        "DRIVE_FOLDER = \"/content/drive/MyDrive/BRSR_Reports\"              # input PDFs\n",
        "OUTPUT_ROOT = \"/content/drive/MyDrive/BRSR_Results\"              # where outputs go\n",
        "DB_PATH = \"brsr_database.db\"                                     # local DB file in working dir (copy to Drive at end)\n",
        "OCR_IF_EMPTY = True\n",
        "FUZZY_THRESHOLD = 80\n",
        "SNIPPETS_PER_KEYWORD = 3\n",
        "ASSUME_FULL_MENTIONS = 3\n",
        "\n",
        "# Keyword list (kept same as requested)\n",
        "KEYWORDS = [\n",
        "    \"Sustainability Report\",\n",
        "    \"Greenhouse Gas Emissions\",\n",
        "    \"Stakeholder Engagement\",\n",
        "    \"Governance Policies\",\n",
        "    \"Employee Wellbeing\",\n",
        "    \"Human Rights\",\n",
        "    \"Materiality Assessment\",\n",
        "    \"Data Protection\",\n",
        "    \"Privacy Impact Assessment\",\n",
        "    \"Business Responsibility and Sustainability Report\"\n",
        "]\n",
        "\n",
        "# Create output folder for this run\n",
        "ts = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "OUTDIR = os.path.join(OUTPUT_ROOT, f\"auto_run_{ts}\")\n",
        "os.makedirs(OUTDIR, exist_ok=True)\n",
        "LOG_PATH = os.path.join(OUTDIR, \"run_log.txt\")\n",
        "\n",
        "def log(msg):\n",
        "    print(msg)\n",
        "    with open(LOG_PATH, \"a\", encoding=\"utf-8\") as lf:\n",
        "        lf.write(f\"{datetime.datetime.now().isoformat()}  {msg}\\n\")\n",
        "\n",
        "log(f\"Starting BRSR automation run. Output => {OUTDIR}\")\n",
        "\n",
        "# -----------------------\n",
        "# Ensure Drive is mounted\n",
        "# -----------------------\n",
        "from google.colab import drive\n",
        "try:\n",
        "    drive.mount('/content/drive', force_remount=False)\n",
        "    log(\"Drive mounted.\")\n",
        "except Exception as e:\n",
        "    log(f\"Drive mount error (continuing if already mounted): {e}\")\n",
        "\n",
        "# -----------------------\n",
        "# Database helpers\n",
        "# -----------------------\n",
        "conn = sqlite3.connect(DB_PATH)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Create tables if they don't exist\n",
        "cursor.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS Company_Reports (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    company_name TEXT NOT NULL,\n",
        "    report_type TEXT NOT NULL,\n",
        "    report_year INTEGER,\n",
        "    file_path TEXT NOT NULL UNIQUE,\n",
        "    url TEXT,\n",
        "    download_date TEXT\n",
        ");\n",
        "\"\"\")\n",
        "cursor.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS Compliance_Scores (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    report_id INTEGER NOT NULL,\n",
        "    score REAL NOT NULL,\n",
        "    assessment_date TEXT NOT NULL,\n",
        "    keyword_counts TEXT,\n",
        "    FOREIGN KEY (report_id) REFERENCES Company_Reports (id)\n",
        ");\n",
        "\"\"\")\n",
        "cursor.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS Regulatory_Updates (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    date TEXT NOT NULL,\n",
        "    title TEXT NOT NULL,\n",
        "    link TEXT NOT NULL\n",
        ");\n",
        "\"\"\")\n",
        "conn.commit()\n",
        "log(\"Database (tables) ready in \" + DB_PATH)\n",
        "\n",
        "def report_exists(file_path):\n",
        "    cursor.execute(\"SELECT id FROM Company_Reports WHERE file_path = ?\", (file_path,))\n",
        "    r = cursor.fetchone()\n",
        "    return r[0] if r else None\n",
        "\n",
        "def insert_company_report(company_name, report_type, report_year, file_path, url=None, download_date=None):\n",
        "    # If already exists, return id\n",
        "    existing = report_exists(file_path)\n",
        "    if existing:\n",
        "        return existing\n",
        "    cursor.execute(\"\"\"\n",
        "        INSERT INTO Company_Reports (company_name, report_type, report_year, file_path, url, download_date)\n",
        "        VALUES (?, ?, ?, ?, ?, ?)\n",
        "    \"\"\", (company_name, report_type, report_year, file_path, url or 'N/A', download_date))\n",
        "    conn.commit()\n",
        "    return cursor.lastrowid\n",
        "\n",
        "def insert_compliance_score(report_id, score, assessment_date, keyword_counts):\n",
        "    kc_json = json.dumps(keyword_counts, ensure_ascii=False)\n",
        "    cursor.execute(\"\"\"\n",
        "        INSERT INTO Compliance_Scores (report_id, score, assessment_date, keyword_counts)\n",
        "        VALUES (?, ?, ?, ?)\n",
        "    \"\"\", (report_id, score, assessment_date, kc_json))\n",
        "    conn.commit()\n",
        "    return cursor.lastrowid\n",
        "\n",
        "# -----------------------\n",
        "# Text extraction helpers\n",
        "# -----------------------\n",
        "def ocr_page_image(page):\n",
        "    try:\n",
        "        img = page.to_image(resolution=200).original\n",
        "        return pytesseract.image_to_string(img)\n",
        "    except Exception as e:\n",
        "        return \"\"\n",
        "\n",
        "def extract_text_from_pdf(pdf_path, ocr_if_empty=True):\n",
        "    texts = []\n",
        "    try:\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            for p in pdf.pages:\n",
        "                page_text = p.extract_text() or \"\"\n",
        "                if (not page_text or len(page_text.strip()) < 40) and ocr_if_empty:\n",
        "                    page_text = ocr_page_image(p) or page_text\n",
        "                texts.append(page_text)\n",
        "    except Exception as e:\n",
        "        log(f\"Error reading {pdf_path}: {e}\")\n",
        "    return \"\\n\".join(texts)\n",
        "\n",
        "# -----------------------\n",
        "# Scoring function (simple presence + frequency log)\n",
        "# -----------------------\n",
        "def calculate_brsr_compliance_score(text, keywords):\n",
        "    text_low = text.lower()\n",
        "    keyword_counts = {kw: text_low.count(kw.lower()) for kw in keywords}\n",
        "    found = sum(1 for v in keyword_counts.values() if v > 0)\n",
        "    total = len(keywords)\n",
        "    score = (found / total) * 100 if total else 0\n",
        "    return score, keyword_counts\n",
        "\n",
        "# -----------------------\n",
        "# Process PDFs in DRIVE_FOLDER\n",
        "# -----------------------\n",
        "if not os.path.exists(DRIVE_FOLDER):\n",
        "    log(f\"Input folder does not exist: {DRIVE_FOLDER}. Please create it and upload PDFs.\")\n",
        "    raise SystemExit(\"Input folder missing.\")\n",
        "\n",
        "# company name mapping heuristics\n",
        "company_map = {\n",
        "    \"infosys\": \"Infosys\",\n",
        "    \"tcs\": \"TCS\",\n",
        "    \"wipro\": \"Wipro\",\n",
        "    \"hcltech\": \"HCLTech\",\n",
        "    \"tml\": \"Tata Motors\",\n",
        "    \"tatamotors\": \"Tata Motors\",\n",
        "    \"tatamotorslimited\": \"Tata Motors\"\n",
        "}\n",
        "\n",
        "processed = []\n",
        "skipped = []\n",
        "\n",
        "for entry in sorted(os.listdir(DRIVE_FOLDER)):\n",
        "    if not entry.lower().endswith(\".pdf\"):\n",
        "        continue\n",
        "    pdf_path = os.path.join(DRIVE_FOLDER, entry)\n",
        "    log(f\"Found PDF: {pdf_path}\")\n",
        "\n",
        "    # Skip if already processed (by file_path)\n",
        "    rep_id = report_exists(pdf_path)\n",
        "    if rep_id:\n",
        "        log(f\" - Skipping (already in DB) : {entry}\")\n",
        "        skipped.append(entry)\n",
        "        continue\n",
        "\n",
        "    # infer company from filename (first token)\n",
        "    key = Path(entry).stem.split(\"_\")[0].lower()\n",
        "    company_name = company_map.get(key, key.capitalize())\n",
        "\n",
        "    # extract text and save txt alongside the PDF in Drive\n",
        "    text = extract_text_from_pdf(pdf_path, ocr_if_empty=OCR_IF_EMPTY)\n",
        "    txt_name = os.path.splitext(entry)[0] + \".txt\"\n",
        "    txt_path_drive = os.path.join(DRIVE_FOLDER, txt_name)\n",
        "    try:\n",
        "        with open(txt_path_drive, \"w\", encoding=\"utf-8\") as tf:\n",
        "            tf.write(text)\n",
        "        log(f\" - Saved TXT: {txt_path_drive}\")\n",
        "    except Exception as e:\n",
        "        log(f\" - Could not save TXT: {e}\")\n",
        "\n",
        "    # calculate score\n",
        "    score, counts = calculate_brsr_compliance_score(text, KEYWORDS)\n",
        "    log(f\" - Score for {company_name}: {score:.2f} (found {sum(1 for v in counts.values() if v>0)}/{len(KEYWORDS)})\")\n",
        "\n",
        "    # insert into DB\n",
        "    report_id = insert_company_report(\n",
        "        company_name=company_name,\n",
        "        report_type=\"Annual Report\",\n",
        "        report_year=None,\n",
        "        file_path=pdf_path,\n",
        "        url=None,\n",
        "        download_date=str(datetime.date.today())\n",
        "    )\n",
        "\n",
        "    insert_compliance_score(\n",
        "        report_id=report_id,\n",
        "        score=score,\n",
        "        assessment_date=str(datetime.date.today()),\n",
        "        keyword_counts=counts\n",
        "    )\n",
        "\n",
        "    processed.append((entry, score))\n",
        "    log(f\" - Inserted DB rows for {entry}\")\n",
        "\n",
        "# -----------------------\n",
        "# Export CSVs to Drive\n",
        "# -----------------------\n",
        "try:\n",
        "    conn.commit()\n",
        "    df_reports = pd.read_sql_query(\"SELECT * FROM Company_Reports\", conn)\n",
        "    df_scores = pd.read_sql_query(\"SELECT * FROM Compliance_Scores\", conn)\n",
        "    df_updates = pd.read_sql_query(\"SELECT * FROM Regulatory_Updates\", conn)\n",
        "    csv_folder = os.path.join(OUTPUT_ROOT, \"CSV_Exports\")\n",
        "    os.makedirs(csv_folder, exist_ok=True)\n",
        "    df_reports.to_csv(os.path.join(csv_folder, \"Company_Reports.csv\"), index=False)\n",
        "    df_scores.to_csv(os.path.join(csv_folder, \"Compliance_Scores.csv\"), index=False)\n",
        "    df_updates.to_csv(os.path.join(csv_folder, \"Regulatory_Updates.csv\"), index=False)\n",
        "    log(f\"Exported CSVs to {csv_folder}\")\n",
        "except Exception as e:\n",
        "    log(f\"CSV export error: {e}\")\n",
        "\n",
        "# -----------------------\n",
        "# Copy DB and outputs into OUTDIR (Drive)\n",
        "# -----------------------\n",
        "try:\n",
        "    # copy DB into OUTDIR on Drive (so DB saved in Drive)\n",
        "    shutil.copy(DB_PATH, os.path.join(OUTDIR, os.path.basename(DB_PATH)))\n",
        "    log(\"Copied DB into OUTDIR in Drive.\")\n",
        "\n",
        "    # optional: zip the OUTDIR for download\n",
        "    zip_base = os.path.join(\"/content\", f\"brsr_results_{ts}\")\n",
        "    shutil.make_archive(zip_base, 'zip', OUTDIR)\n",
        "    zip_path = zip_base + \".zip\"\n",
        "    log(f\"Created ZIP backup: {zip_path}\")\n",
        "except Exception as e:\n",
        "    log(f\"Error saving outputs: {e}\")\n",
        "\n",
        "# -----------------------\n",
        "# Final printout\n",
        "# -----------------------\n",
        "log(f\"Processed {len(processed)} new PDFs. Skipped {len(skipped)} already-processed files.\")\n",
        "log(\"Run completed. Check results in Drive: \" + OUTDIR)\n",
        "log(\"CSV exports: \" + os.path.join(OUTPUT_ROOT, \"CSV_Exports\"))\n",
        "\n",
        "# Close DB\n",
        "conn.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6W0z9ENiRVJ8",
        "outputId": "b891944c-d0c1-4393-96a3-de198da03d1d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/drive/MyDrive/BRSR_Automation/brsr_automation.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One liner code for Automation\n",
        "# !python3 /content/drive/MyDrive/BRSR_Automation/brsr_automation.py"
      ],
      "metadata": {
        "id": "jF18Eh7DRWlD"
      },
      "execution_count": 54,
      "outputs": []
    }
  ]
}